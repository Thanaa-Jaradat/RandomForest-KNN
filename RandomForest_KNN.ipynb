{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sl\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from matplotlib.colors import ListedColormap\n",
    "df = pd.read_csv('pima-indians-diabetes.csv', encoding='utf-8')\n",
    "# I ran print(df.duplicated().sum()) to find if there were any duplicates... but there isn't\n",
    "columns = ['Preg', 'Plas', 'Pres', 'skin', 'test', 'mass']\n",
    "val = []\n",
    "# finding number of zeros in each column\n",
    "#if for example I had a 0 value in skin column, it wouldn't make any sense\n",
    "for column in columns:\n",
    "      val.append(len(df[df[column] == 0]))\n",
    "zeros = pd.DataFrame(val, index = columns, columns = ['zeros'])\n",
    "print(zeros)\n",
    "#replacing zero values with mean value\n",
    "for column in columns:\n",
    "    df[column] = df[column].replace(0,np.NaN)\n",
    "    mean = int(df[column].mean(skipna = True))\n",
    "    df[column] = df[column].replace(np.NaN, mean)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.boxplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding if there is a correlation between 'test' and 'class' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T00:28:01.997628Z",
     "start_time": "2025-06-22T00:28:01.178714Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "sns.stripplot(y = 'test', data = df, x = 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting and removing outliers using z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(df['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "# getting the positions of the outliers and dropping the corresponding records\n",
    "i = np.where(z > 3)\n",
    "df.drop(index = i[0], inplace = True)\n",
    "# printing count of total records after dropping outliers\n",
    "print(df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset (60% training, 20% validation, 20% testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Preg', 'Plas', 'Pres', 'skin', 'test', 'mass', 'pedi', 'age']]\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2022)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25,\n",
    "                                                  random_state=2022) # 0.25 * 0.80 = 0.20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Preg', 'Plas', 'Pres', 'skin', 'test', 'mass', 'pedi', 'age']\n",
    "forest = RandomForestClassifier(random_state=2022)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the best 3 attributes are 'Plas', 'mass', 'age'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best K and printing the confusion matrix of each dataset for each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1, 4)\n",
    "accuracies_train = []\n",
    "accuracies_val = []\n",
    "accuracies_test = []\n",
    "report_train = []\n",
    "report_val = []\n",
    "report_test = []\n",
    "x_prime = df[['Plas', 'mass', 'age']]\n",
    "X_prime_train, X_prime_test, y_prime_train, y_prime_test = train_test_split(x_prime, y, test_size=0.2, random_state=2022)\n",
    "X_prime_train, X_prime_val, y_prime_train, y_prime_val = train_test_split(X_prime_train, y_prime_train, test_size=0.25,\n",
    "                                                  random_state=2022)\n",
    "# Loop over K values\n",
    "for i, k in enumerate(neighbors):\n",
    "    knn_train = KNeighborsClassifier(n_neighbors=k, metric = 'minkowski')\n",
    "    knn_train.fit(X_prime_train, y_prime_train)\n",
    "    y_predicted = knn_train.predict(X_prime_train)\n",
    "    accuracy = metrics.accuracy_score(y_prime_train, y_predicted)\n",
    "    accuracies_train.append(accuracy)\n",
    "    report = metrics.classification_report(y_prime_train, y_predicted)\n",
    "    report_train.append(report)\n",
    "    print(\"Confusion matrix for k = \" + str(i + 1) + \" in training set\" + \"\\t\")\n",
    "    print(metrics.confusion_matrix(y_prime_train, y_predicted))\n",
    "    print(\"\\n\")\n",
    "\n",
    "for i, k in enumerate(neighbors):\n",
    "    knn_val = KNeighborsClassifier(n_neighbors=k, metric = 'minkowski')\n",
    "    knn_val.fit(X_prime_train, y_prime_train)\n",
    "    y_predicted = knn_val.predict(X_prime_val)\n",
    "    accuracy = metrics.accuracy_score(y_prime_val, y_predicted)\n",
    "    accuracies_val.append(accuracy)\n",
    "    report = metrics.classification_report(y_prime_val, y_predicted)\n",
    "    report_val.append(report)\n",
    "    print(\"Confusion matrix for k = \" + str(i + 1) + \" in validation set\" + \"\\t\")\n",
    "    print(metrics.confusion_matrix(y_prime_val, y_predicted))\n",
    "    print(\"\\n\")\n",
    "\n",
    "for i, k in enumerate(neighbors):\n",
    "    knn_test = KNeighborsClassifier(n_neighbors=k, metric = 'minkowski')\n",
    "    knn_test.fit(X_prime_train, y_prime_train)\n",
    "    y_predicted = knn_test.predict(X_prime_test)\n",
    "    accuracy = metrics.accuracy_score(y_prime_test, y_predicted)\n",
    "    accuracies_test.append(accuracy)\n",
    "    report = metrics.classification_report(y_prime_test, y_predicted)\n",
    "    report_test.append(report)\n",
    "    print(\"Confusion matrix for k = \" + str(i + 1) + \" in testing set\" + \"\\t\")\n",
    "    print(metrics.confusion_matrix(y_prime_test, y_predicted))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "k_max_train = max((accuracies_train))\n",
    "print(accuracies_train)\n",
    "print(\"best k for TRAINING at index: \" + str(accuracies_train.index(k_max_train)))\n",
    "k_max_val = max((accuracies_val))\n",
    "print(accuracies_val)\n",
    "print(\"best k for VALIDATING at index: \" + str(accuracies_val.index(k_max_val)))\n",
    "k_max_test = max((accuracies_test))\n",
    "print(accuracies_test)\n",
    "print(\"best k for TESTING at index: \" + str(accuracies_test.index(k_max_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing classification report for each k of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Printing for each k the corresponding report of each data set\")\n",
    "for i in range(0, 3):\n",
    "    print(report_train[i] + report_val[i] + report_test[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_s_df = X_prime_train[['Plas', 'mass']] \n",
    "y_s = y_prime_train\n",
    "knn_plot_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_plot_classifier.fit(X_s_df, y_s)\n",
    "\n",
    "# converting 2-feature dataframe to a numpy array \n",
    "X_s = X_s_df.values\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_s[:, 0].min() - 1, stop = X_s[:, 0].max() + 1, step = 1),\n",
    "                     np.arange(start = X_s[:, 1].min() - 1, stop = X_s[:, 1].max() + 1, step = 0.5))\n",
    "\n",
    "plt.contourf(X1, X2, knn_plot_classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('salmon', 'dodgerblue')))\n",
    "\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "\n",
    "for i, j in enumerate(np.unique(y_s)):\n",
    "    plt.scatter(X_s[y_s == j, 0], X_s[y_s == j, 1],\n",
    "                color = ListedColormap(('red', 'blue'))(i), label = j)\n",
    "\n",
    "plt.title('K-NN (Training Set Visualization)')\n",
    "plt.xlabel('Plasma Glucose Concentration (Plas)')\n",
    "plt.ylabel('Body Mass Index (mass)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
